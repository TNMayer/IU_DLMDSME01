{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5a50fe-e55a-422f-b4a6-88db064dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jenkspy import JenksNaturalBreaks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, f1_score, recall_score, roc_curve, auc\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "from tensorflow.keras import layers\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "import sqlite3\n",
    "\n",
    "import modules.feature_selection as fs\n",
    "import modules.helper_functions as hf\n",
    "import modules.filter_rows as fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0d8e7-5cac-4ab2-87f9-bd0f50f5b9be",
   "metadata": {},
   "source": [
    "# Implementing of the routing algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892dd1c2-0f35-4aa4-ac8f-93f5e64d4f2e",
   "metadata": {},
   "source": [
    "In order to bring the application to production and test the approach on live-data it is important to implement several pre-conditions to be able to do so. First the necessary features have to be extracted from the available data. The important features for the machine learning model are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cead2132-3630-4e3a-b37e-f508c7f0afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hf.loadPickle('./models/xgb_clf_final.pkl')\n",
    "features = hf.loadPickle('./models/xgb_clf_final_features.pkl')\n",
    "parameters = hf.loadPickle('./data/parameters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4365720e-5e56-4dce-ab9f-c8c25f1a3d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_split_iloc': 19244,\n",
       " 'jenks': [0, 99, 175, 247, 330, 10000],\n",
       " 'scaler': MinMaxScaler(),\n",
       " 'scale_columns': ['amount', 'dayOfMonth', 'minuteOfDay']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f3c0d0-f821-43a2-8f11-c02d263f69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount',\n",
       " '3D_secured',\n",
       " 'failPrevious',\n",
       " 'failed_UK_Card',\n",
       " 'dayOfMonth',\n",
       " 'minuteOfDay',\n",
       " 'PSP_SR',\n",
       " 'PSP_card_SR',\n",
       " 'PSP_card_3D_secured_SR',\n",
       " 'PSP_card_3D_secured_amountgroup_word_SR',\n",
       " 'PSP_e10_SR',\n",
       " 'PSP_e100_SR',\n",
       " 'PSP_card_e10_SR',\n",
       " 'PSP_card_e200_SR',\n",
       " 'PSP_card_3D_secured_e200_SR',\n",
       " 'PSP_t6h_SR',\n",
       " 'PSP_t12h_SR',\n",
       " 'PSP_Moneycard',\n",
       " 'PSP_UK_Card',\n",
       " 'card_Visa']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f2ae17-1cf3-4f44-8398-4d711c855263",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDb = './data/PSP_Data.sqlite'\n",
    "if hf.checkIfTableDbExists(pathDb, \"X_test\"):\n",
    "    X_test = hf.readSqlTable(pathDb, \"X_test\")\n",
    "    y_test = hf.readSqlTable(pathDb, \"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb6bd00-6319-4d49-afd3-76446360b73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635982379217994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.validate_classifier(model, X_test, y_test, selected_features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147bb5cc-bc89-4870-be7e-a9a9418fb18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(pathDb)\n",
    "data = pd.read_sql(\"SELECT * FROM TB003_DATA_PREPARED WHERE TB003_DATA_PREPARED.[index] = 27490\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94792168-53ed-4d49-a26e-11eb9faa2d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-02-28 23:48:19'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tmsp'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4652b9a-4357-4c53-a2d1-330476745cab",
   "metadata": {},
   "source": [
    "The most data history (all available) is needed to extract the features ```PSP_card_3D_secured_amountgroup_word_expanding_SR```, ```PSP_card_3D_secured_rolling_t21600_SR``` and ```overallSR```. The first feature is the success rate for the PSP to route to, given the card type, the 3D_secured status of the card and the respective amountgroup of the transaction. The second feature is the success rate for the PSP to route to, given the card type and the 3D_secured status within the past 6 hours. The third feature is just the overall success rate for all available transactions. All features rely on the assumption of already cleaned data. All features can be calculated on the fly with database queries. Therefore a database with cleaned transactions have to be created and also updated, as soon as the success status of a transaction is known. This will be done in a next step. Therefore a SQLite database will be created containing one table with all cleaned transactions. This table will be updated as soon as the success status of a new transaction becomes available. Beside that the column ```amountgroup_word``` has to be created which is done using Jenks natural breaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab073b-2f81-461a-88a9-5185e40606b2",
   "metadata": {},
   "source": [
    "We start by defining a simple example, which extends the current "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fd72ca-ca47-442c-aba1-656e631efe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(timestamp, amount, card, country, secured, psp_list, parameters):\n",
    "    \n",
    "    example_timestamp = pd.Timestamp(timestamp)\n",
    "    example_amount = amount\n",
    "    example_card = card\n",
    "    example_country = country\n",
    "    example_3D_secured = secured\n",
    "\n",
    "    example = pd.DataFrame({\"tmsp\": [example_timestamp, example_timestamp, example_timestamp, example_timestamp], \n",
    "                            \"country\": [example_country, example_country, example_country, example_country], \n",
    "                            \"amount\": [example_amount, example_amount, example_amount, example_amount], \n",
    "                            \"card\": [example_card, example_card, example_card, example_card],\n",
    "                            \"3D_secured\": [example_3D_secured, example_3D_secured, example_3D_secured, example_3D_secured],\n",
    "                            \"PSP\": psp_list\n",
    "                           })\n",
    "    \n",
    "    example = hf.get_amountgroups(example, bins = parameters[\"jenks\"])\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e212d86-5816-4916-ad6c-6731d3b612f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failFeatures(data, path_db = './data/PSP_Data.sqlite', table = 'TB003_DATA_PREPARED', delete = False):\n",
    "    \n",
    "    out = data.copy()\n",
    "    cutoff_time = str(data.tmsp.iloc[0] + pd.Timedelta(minutes = -1))\n",
    "    conn = sqlite3.connect(path_db)\n",
    "    duplicates = pd.read_sql(\n",
    "    f\"\"\"\n",
    "        SELECT * FROM {table}\n",
    "        WHERE \n",
    "            (country = '{out.country[0]}') AND\n",
    "            (amount = {out.amount[0]}) AND\n",
    "            (tmsp >= '{cutoff_time}') AND\n",
    "            (tmsp <= '{str(out.tmsp.iloc[0])}')\n",
    "    \"\"\", conn\n",
    "    )\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        if delete:\n",
    "            out['failPrevious'] = 1\n",
    "            for psp in list(out.PSP):\n",
    "                out['failed_' + psp] = duplicates['failed_' + psp][0]\n",
    "            out['failed_' + duplicates.PSP[0]] = 1\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(f\"DELETE FROM {table} WHERE {table}.[index] IN ({', '.join([str(x) for x in duplicates['index']])})\")\n",
    "            conn.commit()\n",
    "            print(\"=== Redundant entries removed from database ===\")\n",
    "        else:\n",
    "            out[\"failPrevious\"] = duplicates[\"failPrevious\"][0]\n",
    "            for psp in list(out.PSP):\n",
    "                out['failed_' + psp] = duplicates['failed_' + psp][0]\n",
    "            out['failed_' + duplicates.PSP[0]] = 1\n",
    "    else:\n",
    "        out['failPrevious'] = 0\n",
    "        for psp in list(out.PSP):\n",
    "            out['failed_' + psp] = 0\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "629a3376-9e2f-43a8-80bf-8f4b028aa36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(data):\n",
    "    out = data.copy()\n",
    "    hours = out[\"tmsp\"].dt.hour\n",
    "    minutes = out[\"tmsp\"].dt.minute\n",
    "    day = out[\"tmsp\"].dt.day\n",
    "    out[\"minuteOfDay\"] = hours*60 + minutes\n",
    "    out[\"dayOfMonth\"] = day\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c5df20-9ebc-4e83-873a-a15870b019bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinatoric_SR(data, pathDb, table, parameters):\n",
    "    out = data.copy()\n",
    "    rowNum = parameters[\"train_split_iloc\"]\n",
    "    conn = sqlite3.connect(pathDb)\n",
    "    psp_sr = pd.read_sql(f\"\"\"\n",
    "        SELECT PSP, AVG(SUCCESS) AS PSP_SR FROM {table}\n",
    "        WHERE ROWID <= {rowNum}\n",
    "        GROUP BY PSP\n",
    "    \"\"\", conn)\n",
    "    out = out.merge(psp_sr, how=\"left\", on = [\"PSP\"])\n",
    "    psp_card_sr = pd.read_sql(f\"\"\"\n",
    "        SELECT PSP, card, AVG(SUCCESS) AS PSP_card_SR FROM {table}\n",
    "        WHERE ROWID <= {rowNum}\n",
    "        GROUP BY PSP, card\n",
    "    \"\"\", conn)\n",
    "    out = out.merge(psp_card_sr, how=\"left\", on = [\"PSP\", \"card\"])\n",
    "    psp_card_sec_sr = pd.read_sql(f\"\"\"\n",
    "        SELECT PSP, card, TB003_DATA_PREPARED.[3D_secured], AVG(SUCCESS) AS PSP_card_3D_secured_SR FROM TB003_DATA_PREPARED\n",
    "        WHERE ROWID <= {rowNum}\n",
    "        GROUP BY PSP, card, TB003_DATA_PREPARED.[3D_secured]\n",
    "    \"\"\", conn)\n",
    "    out = out.merge(psp_card_sec_sr, how=\"left\", on = [\"PSP\", \"card\", \"3D_secured\"])\n",
    "    psp_card_sec_amountgroup_sr = pd.read_sql(f\"\"\"\n",
    "        SELECT PSP, card, TB003_DATA_PREPARED.[3D_secured], \n",
    "            amountgroup_word, \n",
    "            AVG(SUCCESS) AS PSP_card_3D_secured_amountgroup_word_SR FROM TB003_DATA_PREPARED\n",
    "        WHERE ROWID <= {rowNum}\n",
    "        GROUP BY PSP, card, TB003_DATA_PREPARED.[3D_secured], amountgroup_word\n",
    "    \"\"\", conn)\n",
    "    out = out.merge(psp_card_sec_amountgroup_sr, how=\"left\", on = [\"PSP\", \"card\", \"3D_secured\", \"amountgroup_word\"])\n",
    "    conn.close()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d00e8f07-2c61-4781-af33-accae943cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinatoric_event_window_SR(data, pathDb = './data/PSP_Data.sqlite', table = \"TB003_DATA_PREPARED\", event_window = 10):\n",
    "    out = data.copy()\n",
    "    tmsp = str(out.tmsp.iloc[0])\n",
    "    conn = sqlite3.connect(pathDb)\n",
    "    psps = out[\"PSP\"]\n",
    "    card = out.card.iloc[0]\n",
    "    secured = out[\"3D_secured\"].iloc[0]\n",
    "    amountgroup = out[\"amountgroup_word\"].iloc[0]\n",
    "    out[\"PSP_e\" + str(event_window) + \"_SR\"] = 0\n",
    "    out[\"PSP_card_e\" + str(event_window) + \"_SR\"] = 0\n",
    "    out[\"PSP_card_3D_secured_e\" + str(event_window) + \"_SR\"] = 0\n",
    "    for psp in psps:\n",
    "        psp_sr = pd.read_sql(f\"\"\"\n",
    "            SELECT AVG(success) FROM\n",
    "            (SELECT tmsp, PSP, success FROM {table}\n",
    "            WHERE tmsp < '{tmsp}' AND PSP = '{psp}'\n",
    "            ORDER BY tmsp DESC\n",
    "            LIMIT {event_window})\n",
    "        \"\"\", conn)\n",
    "        out[\"PSP_e\" + str(event_window) + \"_SR\"] = np.where(out[\"PSP\"] == psp, psp_sr.iloc[0, 0], out[\"PSP_e\" + str(event_window) + \"_SR\"])\n",
    "        out[\"PSP_e\" + str(event_window) + \"_SR\"] = out[\"PSP_e\" + str(event_window) + \"_SR\"].fillna(out[\"PSP_SR\"])\n",
    "        psp_card_sr = pd.read_sql(f\"\"\"\n",
    "            SELECT AVG(success) FROM\n",
    "            (SELECT tmsp, card, PSP, success FROM {table}\n",
    "            WHERE tmsp < '{tmsp}' AND PSP = '{psp}' AND card = '{card}'\n",
    "            ORDER BY tmsp DESC\n",
    "            LIMIT {event_window})\n",
    "        \"\"\", conn)\n",
    "        out[\"PSP_card_e\" + str(event_window) + \"_SR\"] = np.where(out[\"PSP\"] == psp, \n",
    "                                                                 psp_card_sr.iloc[0, 0], \n",
    "                                                                 out[\"PSP_card_e\" + str(event_window) + \"_SR\"])\n",
    "        out[\"PSP_card_e\" + str(event_window) + \"_SR\"] = out[\"PSP_card_e\" + str(event_window) + \"_SR\"].fillna(out[\"PSP_card_SR\"])\n",
    "        psp_card_secured_sr = pd.read_sql(f\"\"\"\n",
    "            SELECT AVG(success) FROM\n",
    "            (SELECT tmsp, card, PSP, {table}.[3D_secured], success FROM {table}\n",
    "            WHERE tmsp < '{tmsp}' AND PSP = '{psp}' AND card = '{card}' AND {table}.[3D_secured] = {secured}\n",
    "            ORDER BY tmsp DESC\n",
    "            LIMIT {event_window})\n",
    "        \"\"\", conn)\n",
    "        out[\"PSP_card_3D_secured_e\" + str(event_window) + \"_SR\"] = np.where(out[\"PSP\"] == psp, \n",
    "                                                                            psp_card_secured_sr.iloc[0, 0], \n",
    "                                                                            out[\"PSP_card_3D_secured_e\" + str(event_window) + \"_SR\"])\n",
    "        out[\"PSP_card_3D_secured_e\" + str(event_window) + \"_SR\"] = out[\"PSP_card_3D_secured_e\" + str(event_window) + \"_SR\"].fillna(out[\"PSP_card_3D_secured_SR\"])\n",
    "    conn.close()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec82e0e1-e221-4c85-a2ae-46d0ee5bab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinatoric_time_window_SR(data, pathDb = './data/PSP_Data.sqlite', table = \"TB003_DATA_PREPARED\", time_window = 6):\n",
    "    out = data.copy()\n",
    "    timestamp = pd.Timestamp(out.tmsp.iloc[0])\n",
    "    cutoff_time = str(timestamp + pd.Timedelta(hours = -time_window))\n",
    "    conn = sqlite3.connect(pathDb)\n",
    "    out[\"PSP_t\" + str(time_window) + \"h_SR\"] = 0\n",
    "    for psp in out.PSP:\n",
    "        outcome = pd.read_sql(f\"\"\"\n",
    "            SELECT AVG(success) AS PSP_t{time_window}h_SR FROM {table}\n",
    "            WHERE PSP = '{psp}' AND tmsp >= '{cutoff_time}' AND tmsp < '{str(timestamp)}'\n",
    "        \"\"\", conn)\n",
    "        out[\"PSP_t\" + str(time_window) + \"h_SR\"] = np.where(out[\"PSP\"] == psp, outcome.iloc[0, 0], out[\"PSP_t\" + str(time_window) + \"h_SR\"])\n",
    "    conn.close()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b8aa57-c0e5-463d-b7ab-b260d7492fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_features(data, columns = [\"PSP\", 'card']):\n",
    "    out = data.copy()\n",
    "    for column in columns:\n",
    "        try:\n",
    "            out = pd.get_dummies(out, columns = [column])\n",
    "        except:\n",
    "            print(\"column \" + column + \" already exists\")\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c08bc532-c800-4152-820c-caa84a0161a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missings(data, features):\n",
    "    out = data.copy()\n",
    "    diff = list(set(features) - set(out.columns))\n",
    "    \n",
    "    if len(diff) > 0:\n",
    "        for col in diff:\n",
    "            out[col] = 0\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d983b2b2-ad4b-4386-b0e2-a6035316fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(data, parameters):\n",
    "    out = data.copy()\n",
    "    scaleCols = parameters[\"scale_columns\"]\n",
    "    out[scaleCols] = parameters[\"scaler\"].transform(out[scaleCols])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1885e841-2cd0-4c5c-bcd0-95bdfb53a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrate(\n",
    "    timestamp, \n",
    "    amount, \n",
    "    card, \n",
    "    country, \n",
    "    secured, \n",
    "    features, \n",
    "    psp_list,\n",
    "    parameters,\n",
    "    pathDb = './data/PSP_Data.sqlite',\n",
    "    table = 'TB003_DATA_PREPARED'):\n",
    "    \n",
    "    example = generate_sample(timestamp, amount, card, country, secured, psp_list, parameters)\n",
    "    example = get_failFeatures(example, table = table)\n",
    "    example = get_time_features(example)\n",
    "    example = get_combinatoric_SR(example, pathDb, table, parameters)\n",
    "    example = get_combinatoric_event_window_SR(example, event_window = 10)\n",
    "    example = get_combinatoric_event_window_SR(example, event_window = 100)\n",
    "    example = get_combinatoric_event_window_SR(example, event_window = 200)\n",
    "    example = get_combinatoric_time_window_SR(example, time_window = 6)\n",
    "    example = get_combinatoric_time_window_SR(example, time_window = 12)\n",
    "    example = get_one_hot_features(example)\n",
    "    example = replace_missings(example, features)\n",
    "    example = scale_features(example, parameters)\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e11800b-2faf-440f-ac77-dc8909ed8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(row_id, features):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    conn = sqlite3.connect(pathDb)\n",
    "    data = pd.read_sql(f\"SELECT * FROM TB003_DATA_PREPARED WHERE TB003_DATA_PREPARED.[index] = {row_id}\", conn)\n",
    "    conn.close()\n",
    "    \n",
    "    fee_dict = {\"Goldcard\": 10, \"Simplecard\": 1, \"Moneycard\": 5, \"UK_Card\": 3}\n",
    "    example = orchestrate(\n",
    "        timestamp = str(pd.Timestamp(data['tmsp'].iloc[0]) + pd.Timedelta(seconds = 1)),\n",
    "        amount = data['amount'].iloc[0],\n",
    "        card = data['card'].iloc[0],\n",
    "        country = data['country'].iloc[0],\n",
    "        secured = data['3D_secured'].iloc[0],\n",
    "        features = features,\n",
    "        psp_list = list(fee_dict.keys()),\n",
    "        parameters = parameters\n",
    "    )\n",
    "    print(time.time() - start_time)\n",
    "    \n",
    "    out = pd.DataFrame({\"PSP\": fee_dict.keys(), \"probability\": model.predict_proba(example[features])[:, 1], \"fee\": fee_dict.values()})\n",
    "    out = out[out[\"probability\"] >= 0.5]\n",
    "    out = out.sort_values(by = [\"fee\"])\n",
    "    if len(out) == 0:\n",
    "        print(\"Selection defaults to cheapest PSP: Simplecard\")\n",
    "    else:\n",
    "        print(out)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f7e4339-96a4-4da6-a3ec-2aa903acfbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993241548538208\n",
      "       PSP  probability  fee\n",
      "3  UK_Card      0.56187    3\n"
     ]
    }
   ],
   "source": [
    "generate_prediction(27433, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
